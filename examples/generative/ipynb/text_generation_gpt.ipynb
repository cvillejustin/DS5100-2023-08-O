{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5Xc7ki6LMAf"
      },
      "source": [
        "# Codeathon 3, DS 6050, Justin Roberts (jrr4n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6s3dVDsLMAf"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9rwYg4ULMAf",
        "outputId": "c9c58810-37c1-496d-8157-69f9b9f01d21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/644.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m634.9/644.1 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.1/644.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade keras-hub\n",
        "!pip install -q --upgrade keras  # Upgrade to Keras 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "fgub8XT6LMAg"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import keras_hub\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow.data as tf_data\n",
        "import tensorflow.strings as tf_strings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"not available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cjr0o-AwME4A",
        "outputId": "f758c862-887c-48e2-b0a7-513e6a5ffd0d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBNOfr5sLMAg"
      },
      "source": [
        "## Settings & hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "I3xQBomjLMAg"
      },
      "outputs": [],
      "source": [
        "# Data\n",
        "BATCH_SIZE = 64\n",
        "MIN_STRING_LEN = 512  # Strings shorter than this will be discarded\n",
        "SEQ_LEN = 128  # Length of training sequences, in tokens\n",
        "\n",
        "# Model\n",
        "EMBED_DIM = 256\n",
        "FEED_FORWARD_DIM = 128\n",
        "NUM_HEADS = 3\n",
        "NUM_LAYERS = 2\n",
        "VOCAB_SIZE = 5000  # Limits parameters in model.\n",
        "\n",
        "# Training\n",
        "EPOCHS = 5\n",
        "\n",
        "# Inference\n",
        "NUM_TOKENS_TO_GENERATE = 80"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import keras\n",
        "# Get current working directory\n",
        "cwd = os.getcwd()\n",
        "# Download the dataset to the current working directory\n",
        "file_path = keras.utils.get_file(\n",
        "   fname=\"simplebooks.zip\",\n",
        "   origin=\"https://dldata-public.s3.us-east-2.amazonaws.com/simplebooks.zip\",\n",
        "   extract=False,  # Do not extract immediately\n",
        "   cache_dir=cwd  # Save it in the current working directory\n",
        ")\n",
        "# Extract the zip file manually to the current working directory\n",
        "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "   zip_ref.extractall(cwd)\n",
        "# Now set the dataset directory based on your current working directory\n",
        "dir = os.path.join(cwd, \"simplebooks/\")\n",
        "# Load simplebooks-92 train set and filter out short lines.\n",
        "raw_train_ds = (\n",
        "   tf_data.TextLineDataset(dir + \"simplebooks-92-raw/train.txt\")\n",
        "   .filter(lambda x: tf_strings.length(x) > MIN_STRING_LEN)\n",
        "   .batch(BATCH_SIZE)\n",
        "   .shuffle(buffer_size=256)\n",
        ")\n",
        "\n",
        "# Load simplebooks-92 validation set and filter out short lines.\n",
        "raw_val_ds = (\n",
        "   tf_data.TextLineDataset(dir + \"simplebooks-92-raw/valid.txt\")\n",
        "   .filter(lambda x: tf_strings.length(x) > MIN_STRING_LEN)\n",
        "   .batch(BATCH_SIZE)\n",
        ")\n",
        "print(f\"Dataset extracted to: {dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qvisz44cMkSd",
        "outputId": "429e3908-3e6b-472e-abfd-17e61f9a22aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://dldata-public.s3.us-east-2.amazonaws.com/simplebooks.zip\n",
            "\u001b[1m282386239/282386239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 0us/step\n",
            "Dataset extracted to: /content/simplebooks/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "v16t2obNLMAh"
      },
      "outputs": [],
      "source": [
        "# Train tokenizer vocabulary\n",
        "vocab = keras_hub.tokenizers.compute_word_piece_vocabulary(\n",
        "    raw_train_ds,\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    lowercase=True,\n",
        "    reserved_tokens=[\"[PAD]\", \"[UNK]\", \"[BOS]\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9PY3TwFtLMAh"
      },
      "outputs": [],
      "source": [
        "tokenizer = keras_hub.tokenizers.WordPieceTokenizer(\n",
        "    vocabulary=vocab,\n",
        "    sequence_length=SEQ_LEN,\n",
        "    lowercase=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6Xk7OvNSLMAh"
      },
      "outputs": [],
      "source": [
        "# packer adds a start token\n",
        "start_packer = keras_hub.layers.StartEndPacker(\n",
        "    sequence_length=SEQ_LEN,\n",
        "    start_value=tokenizer.token_to_id(\"[BOS]\"),\n",
        ")\n",
        "\n",
        "\n",
        "def preprocess(inputs):\n",
        "    outputs = tokenizer(inputs)\n",
        "    features = start_packer(outputs)\n",
        "    labels = outputs\n",
        "    return features, labels\n",
        "\n",
        "\n",
        "# Tokenize and split into train and label sequences.\n",
        "train_ds = raw_train_ds.map(preprocess, num_parallel_calls=tf_data.AUTOTUNE).prefetch(\n",
        "    tf_data.AUTOTUNE\n",
        ")\n",
        "val_ds = raw_val_ds.map(preprocess, num_parallel_calls=tf_data.AUTOTUNE).prefetch(\n",
        "    tf_data.AUTOTUNE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "siYzef_7LMAi"
      },
      "outputs": [],
      "source": [
        "inputs = keras.layers.Input(shape=(None,), dtype=\"int32\")\n",
        "# Embedding.\n",
        "embedding_layer = keras_hub.layers.TokenAndPositionEmbedding(\n",
        "    vocabulary_size=VOCAB_SIZE,\n",
        "    sequence_length=SEQ_LEN,\n",
        "    embedding_dim=EMBED_DIM,\n",
        "    mask_zero=True,\n",
        ")\n",
        "x = embedding_layer(inputs)\n",
        "# Transformer decoders.\n",
        "for _ in range(NUM_LAYERS):\n",
        "    decoder_layer = keras_hub.layers.TransformerDecoder(\n",
        "        num_heads=NUM_HEADS,\n",
        "        intermediate_dim=FEED_FORWARD_DIM,\n",
        "    )\n",
        "    x = decoder_layer(x)  # Giving one argument only skips cross-attention.\n",
        "# Output.\n",
        "outputs = keras.layers.Dense(VOCAB_SIZE)(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "perplexity = keras_hub.metrics.Perplexity(from_logits=True, mask_token_id=0)\n",
        "model.compile(optimizer=\"adam\", loss=loss_fn, metrics=[perplexity])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "QmflZnyMLMAi",
        "outputId": "8e4465e8-7492-4005-e473-3727d266721b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ token_and_position_embedding         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │       \u001b[38;5;34m1,312,768\u001b[0m │\n",
              "│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_decoder                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m329,085\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_decoder_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m329,085\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerDecoder\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5000\u001b[0m)          │       \u001b[38;5;34m1,285,000\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ token_and_position_embedding         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,312,768</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)          │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_decoder                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">329,085</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_decoder_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">329,085</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecoder</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5000</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,285,000</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,255,938\u001b[0m (12.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,255,938</span> (12.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,255,938\u001b[0m (12.42 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,255,938</span> (12.42 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEfP8S0ILMAi"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYpQm14TLMAi",
        "outputId": "8d2ad094-f952-46a3-bddb-436bc4dfb799"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:932: UserWarning: Layer 'position_embedding' (of type PositionEmbedding) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:932: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:932: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py:932: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   2443/Unknown \u001b[1m142s\u001b[0m 51ms/step - loss: 4.9906 - perplexity: 174.7564"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m2444/2444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 53ms/step - loss: 4.9901 - perplexity: 174.6750 - val_loss: 4.1867 - val_perplexity: 65.9519\n",
            "Epoch 2/5\n",
            "\u001b[1m2444/2444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 49ms/step - loss: 4.1755 - perplexity: 65.1365 - val_loss: 4.1095 - val_perplexity: 61.0230\n",
            "Epoch 3/5\n",
            "\u001b[1m2444/2444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 49ms/step - loss: 4.0333 - perplexity: 56.4843 - val_loss: 4.0263 - val_perplexity: 56.0888\n",
            "Epoch 4/5\n",
            "\u001b[1m2444/2444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 49ms/step - loss: 3.9607 - perplexity: 52.5219 - val_loss: 4.0093 - val_perplexity: 55.1708\n",
            "Epoch 5/5\n",
            "\u001b[1m2444/2444\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 49ms/step - loss: 3.9200 - perplexity: 50.4315 - val_loss: 3.9870 - val_perplexity: 54.0164\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79f3c0284340>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G52YlF4CLMAi"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4eGuFbhLMAi",
        "outputId": "a929437f-9891-49ad-9f6d-febd57ca1d5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
              "array([[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# The \"packer\" layers adds the [BOS] token for us.\n",
        "prompt_tokens = start_packer(tokenizer([\"\"]))\n",
        "prompt_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "R7kEUOAjLMAj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def next(prompt, cache, index):\n",
        "    logits = model(prompt)[:, index - 1, :]\n",
        "    # Ignore hidden states for now; only needed for contrastive search.\n",
        "    hidden_states = None\n",
        "    return logits, hidden_states, cache\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh87dsRKLMAj"
      },
      "source": [
        "### Greedy search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWRvVtzULMAj",
        "outputId": "dee70479-0b85-4c84-deaf-07864b9c7353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greedy search generated text: \n",
            "['[BOS] \" i don \\' t know , \" said the doctor , \" but i \\' m afraid i \\' m afraid i \\' m going to do it . i \\' m afraid i \\' m going to do it . i \\' m going to be a good place , and i \\' m going to get a good deal of trouble . i \\' m going to be a good place , and i \\' m going to get a good deal of trouble . i \\' m going to get a good deal of trouble . i \\' m going to get a good deal of trouble . i \\' m going to get a good deal of trouble . i \\' m']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sampler = keras_hub.samplers.GreedySampler()\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,  # Start sampling immediately after the [BOS] token.\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Greedy search generated text: \\n{txt}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zupks4hfLMAj"
      },
      "source": [
        "### Beam search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0usd_kvsLMAj",
        "outputId": "12025b47-2bc8-48b2-eff3-de731a4534ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beam search generated text: \n",
            "['[BOS] \" i don \\' t know , \" he said , \" but i don \\' t know what i can do . i don \\' t know , but i don \\' t know what to do . i don \\' t know what to do , but i don \\' t know . i don \\' t know what to do , but i don \\' t know what to do . i don \\' t know what to do , but i don \\' t know what to do . i don \\' t know what to do , but i don \\' t know . i don \\' t know what to do . i don \\' t know what to do .']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sampler = keras_hub.samplers.BeamSampler(num_beams=10)\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Beam search generated text: \\n{txt}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV-uJvoPLMAk"
      },
      "source": [
        "### Random search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dImxEXYLMAk",
        "outputId": "d6cffc02-1854-4c73-b9ff-3075a86121ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random search generated text: \n",
            "['[BOS] \" turn your sword well , \" said lang question , chatterer by this time , for he makes up other way along until he could be drivenge or an inch of hab cavalry . of course he was so lucky for his determined experience with the sun . he was not prescitably able to follow him , and he finally got the whip on the rope , and potter was i in closet . and then he made up his mind to proceed from the whip . it was a pigeon with an understanding that he had two arrows when he bent and gloat on , a trip on any account']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sampler = keras_hub.samplers.RandomSampler()\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Random search generated text: \\n{txt}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzJgzswWLMAk"
      },
      "source": [
        "### Top-K search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srz2kkscLMAl",
        "outputId": "0d399ac9-c385-4640-ae6e-69c465394294"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-K search generated text: \n",
            "['[BOS] \" yes , \" said mr . brenton ; \" but you \\' re not the least doubt of you , and it is a bad habitual to say goodby , \" \" \" and a few minutes later he had a good time . \" he will go to the house . but he \\' ll have a good time when he was to wait for a few minutes . you know that he was not a very long , and it had been a chapter , when he saw the young man standing at the edge of the forest , and he had to wait for some time , for he had seen them , and his father had']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sampler = keras_hub.samplers.TopKSampler(k=10)\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Top-K search generated text: \\n{txt}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8NGetGQLMAl"
      },
      "source": [
        "### Top-P search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aJNRT1SLMAl",
        "outputId": "096ac112-c75c-4de7-d9cb-8352f540a429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top-P search generated text: \n",
            "['[BOS] but the esther sparks of flanders , who was conquered and put to death , had been in the battle of the american army . the army had been gathered about the army and marched to england . the french army , as the king , the prince , who had arrived at calcutta , had sent a messenger to him . the duke of seccano , and the news that the whole of the english had to leave the country , and had been received with great force . the french were now seized with an army , and as the spaniards , as it was , they']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sampler = keras_hub.samplers.TopPSampler(p=0.5)\n",
        "output_tokens = sampler(\n",
        "    next=next,\n",
        "    prompt=prompt_tokens,\n",
        "    index=1,\n",
        ")\n",
        "txt = tokenizer.detokenize(output_tokens)\n",
        "print(f\"Top-P search generated text: \\n{txt}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE5nUOPfLMAl"
      },
      "source": [
        "### Using callbacks for text generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgQ8pg5FLMAm",
        "outputId": "21fa631c-fd6b-4c10-dd97-d5638652138c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "Top-K search generated text: \n",
            "['[BOS] \" i was not so much afraid ; he thought it was very strange and very strange to me . i was afraid , but it was very strange and very strange to him i had , but there was something in my mind . i told him that he was a good man , and he would not like to speak to him . then he said : that is that he was going to tell me . then he told me to be a boy , and i would not like him . and when the old man was angry , he had to do his work and he wanted to take a good care of his own . but the boy was so frightened']\n",
            "\n",
            "1/1 - 13s - 13s/step - loss: 3.6836 - perplexity: 39.8201\n",
            "Epoch 2/2\n",
            "Top-K search generated text: \n",
            "['[BOS] \" you see , and , \" he said , \" we are going to be a little more than a hundred times , when a collection of a large sparition of concealing his country and his friends to the capital , and there are few of those who live in apology , for you to live in the same country . you remember that your uncle has got a very good many things that you will not have a good deal to you , and you would find no difficulty in finding out any way to the town . there you are the best to keep quiet in the city . it will be']\n",
            "\n",
            "1/1 - 15s - 15s/step - loss: 3.8676 - perplexity: 47.8676\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79f342bb1f90>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "\n",
        "class TopKTextGenerator(keras.callbacks.Callback):\n",
        "    \"\"\"A callback to generate text from a trained model using top-k.\"\"\"\n",
        "\n",
        "    def __init__(self, k):\n",
        "        self.sampler = keras_hub.samplers.TopKSampler(k)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        output_tokens = self.sampler(\n",
        "            next=next,\n",
        "            prompt=prompt_tokens,\n",
        "            index=1,\n",
        "        )\n",
        "        txt = tokenizer.detokenize(output_tokens)\n",
        "        print(f\"Top-K search generated text: \\n{txt}\\n\")\n",
        "\n",
        "\n",
        "text_generation_callback = TopKTextGenerator(k=10)\n",
        "# Dummy training loop to demonstrate callback.\n",
        "model.fit(train_ds.take(1), verbose=2, epochs=2, callbacks=[text_generation_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Experimenting with GPT2**"
      ],
      "metadata": {
        "id": "2lqsoCgVWM67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/openai/gpt-2.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu5XBIijWLr3",
        "outputId": "738ffc78-5ab1-4e74-f208-d29658085418"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 239, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 239 (delta 1), reused 1 (delta 0), pack-reused 233 (from 1)\u001b[K\n",
            "Receiving objects: 100% (239/239), 4.38 MiB | 18.24 MiB/s, done.\n",
            "Resolving deltas: 100% (125/125), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gpt-2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTueHNltWb79",
        "outputId": "0185a113-e718-4c03-b77d-9cab3eee0ee4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gpt-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# after running once hash out, change the directory in the above line then run the line below this cell to install the requirements file\n",
        "#!pip install -r requirements.txt --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5blsUjOwYAjM",
        "outputId": "c9c70f3f-5c9f-4f0f-9099-d31c376df2a4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fire>=0.1.3 (from -r requirements.txt (line 1))\n",
            "  Using cached fire-0.7.0-py3-none-any.whl\n",
            "Collecting regex==2017.4.5 (from -r requirements.txt (line 2))\n",
            "  Using cached regex-2017.4.5-cp310-cp310-linux_x86_64.whl\n",
            "Collecting requests==2.21.0 (from -r requirements.txt (line 3))\n",
            "  Using cached requests-2.21.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting tqdm==4.31.1 (from -r requirements.txt (line 4))\n",
            "  Using cached tqdm-4.31.1-py2.py3-none-any.whl.metadata (38 kB)\n",
            "Collecting chardet<3.1.0,>=3.0.2 (from requests==2.21.0->-r requirements.txt (line 3))\n",
            "  Using cached chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting idna<2.9,>=2.5 (from requests==2.21.0->-r requirements.txt (line 3))\n",
            "  Using cached idna-2.8-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting urllib3<1.25,>=1.21.1 (from requests==2.21.0->-r requirements.txt (line 3))\n",
            "  Using cached urllib3-1.24.3-py2.py3-none-any.whl.metadata (36 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests==2.21.0->-r requirements.txt (line 3))\n",
            "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting termcolor (from fire>=0.1.3->-r requirements.txt (line 1))\n",
            "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Using cached requests-2.21.0-py2.py3-none-any.whl (57 kB)\n",
            "Using cached tqdm-4.31.1-py2.py3-none-any.whl (48 kB)\n",
            "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
            "Using cached chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "Using cached idna-2.8-py2.py3-none-any.whl (58 kB)\n",
            "Using cached urllib3-1.24.3-py2.py3-none-any.whl (118 kB)\n",
            "Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
            "Installing collected packages: regex, chardet, urllib3, tqdm, termcolor, idna, certifi, requests, fire\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2017.4.5\n",
            "    Uninstalling regex-2017.4.5:\n",
            "      Successfully uninstalled regex-2017.4.5\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 3.0.4\n",
            "    Uninstalling chardet-3.0.4:\n",
            "      Successfully uninstalled chardet-3.0.4\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.31.1\n",
            "    Uninstalling tqdm-4.31.1:\n",
            "      Successfully uninstalled tqdm-4.31.1\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.5.0\n",
            "    Uninstalling termcolor-2.5.0:\n",
            "      Successfully uninstalled termcolor-2.5.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 2.8\n",
            "    Uninstalling idna-2.8:\n",
            "      Successfully uninstalled idna-2.8\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.8.30\n",
            "    Uninstalling certifi-2024.8.30:\n",
            "      Successfully uninstalled certifi-2024.8.30\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.21.0\n",
            "    Uninstalling requests-2.21.0:\n",
            "      Successfully uninstalled requests-2.21.0\n",
            "  Attempting uninstall: fire\n",
            "    Found existing installation: fire 0.7.0\n",
            "    Uninstalling fire-0.7.0:\n",
            "      Successfully uninstalled fire-0.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.22.0 requires requests>=2.27.1, but you have requests 2.21.0 which is incompatible.\n",
            "dopamine-rl 4.0.9 requires tqdm>=4.64.1, but you have tqdm 4.31.1 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.21.0 which is incompatible.\n",
            "huggingface-hub 0.24.7 requires tqdm>=4.42.1, but you have tqdm 4.31.1 which is incompatible.\n",
            "nltk 3.8.1 requires regex>=2021.8.3, but you have regex 2017.4.5 which is incompatible.\n",
            "panel 1.4.5 requires tqdm>=4.48.0, but you have tqdm 4.31.1 which is incompatible.\n",
            "prophet 1.1.6 requires tqdm>=4.36.1, but you have tqdm 4.31.1 which is incompatible.\n",
            "sentry-sdk 2.17.0 requires urllib3>=1.26.11, but you have urllib3 1.24.3 which is incompatible.\n",
            "spacy 3.7.5 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.31.1 which is incompatible.\n",
            "tweepy 4.14.0 requires requests<3,>=2.27.0, but you have requests 2.21.0 which is incompatible.\n",
            "yfinance 0.2.46 requires requests>=2.31, but you have requests 2.21.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed certifi-2024.8.30 chardet-3.0.4 fire-0.7.0 idna-2.8 regex-2017.4.5 requests-2.21.0 termcolor-2.5.0 tqdm-4.31.1 urllib3-1.24.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi"
                ]
              },
              "id": "6426289de98b4790994b889103053589"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0r-zaaiWbzF",
        "outputId": "3b3d612e-4706-4c09-9f0c-bb7b8aa98920"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fire>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (2017.4.5)\n",
            "Requirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n",
            "Requirement already satisfied: tqdm==4.31.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (4.31.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2024.8.30)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 download_model.py 117M"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8XeJZV-Wx_i",
        "outputId": "66557263-057e-4ca4-ac4c-a8aeccb5c399"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching checkpoint: 1.00kit [00:00, 517kit/s]                                                      \n",
            "Fetching encoder.json: 1.04Mit [00:01, 566kit/s]                                                    \n",
            "Fetching hparams.json: 1.00kit [00:00, 538kit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [01:17, 6.40Mit/s]                                  \n",
            "Fetching model.ckpt.index: 6.00kit [00:00, 4.94Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 472kit [00:01, 283kit/s]                                                  \n",
            "Fetching vocab.bpe: 457kit [00:01, 316kit/s]                                                        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gpt-2-simple"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoUy6CxvZa5E",
        "outputId": "81de9776-6924-4ee8-be95-bcb02d61a9e4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gpt-2-simple\n",
            "  Downloading gpt_2_simple-0.8.1.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (2.17.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (2017.4.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (4.31.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (1.26.4)\n",
            "Collecting toposort (from gpt-2-simple)\n",
            "  Downloading toposort-1.10-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.37.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (2024.8.30)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.5.1->gpt-2-simple) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.5.1->gpt-2-simple) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.5.1->gpt-2-simple) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow>=2.5.1->gpt-2-simple) (0.13.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=2.5.1->gpt-2-simple) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=2.5.1->gpt-2-simple) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow>=2.5.1->gpt-2-simple) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow>=2.5.1->gpt-2-simple) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=2.5.1->gpt-2-simple) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow>=2.5.1->gpt-2-simple) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow>=2.5.1->gpt-2-simple) (0.1.2)\n",
            "Downloading toposort-1.10-py3-none-any.whl (8.5 kB)\n",
            "Building wheels for collected packages: gpt-2-simple\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpt-2-simple: filename=gpt_2_simple-0.8.1-py3-none-any.whl size=24556 sha256=9168c0a712452a409fdb955b361c21fb7f213ef013f4eca12f6306dcdafcd4de\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/6a/fe/10d3223f78d1ac3e4c83bb4c5e2d28dfb1789c2fb4cc7ea8d0\n",
            "Successfully built gpt-2-simple\n",
            "Installing collected packages: toposort, gpt-2-simple\n",
            "Successfully installed gpt-2-simple-0.8.1 toposort-1.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls models/117M\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fv9Sr_YZsQJ",
        "outputId": "3768c6e7-bb00-4ab5-fd96-5bad8692bbe0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint    hparams.json\t\t      model.ckpt.index\tvocab.bpe\n",
            "encoder.json  model.ckpt.data-00000-of-00001  model.ckpt.meta\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat models/117M/checkpoint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm2BsDoAaUHS",
        "outputId": "03972605-95bf-4b2e-cdd7-7a5c17f3fec7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_checkpoint_path: \"model.ckpt\"\n",
            "all_model_checkpoint_paths: \"model.ckpt\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gpt_2_simple as gpt2\n",
        "import tensorflow as tf\n",
        "import os"
      ],
      "metadata": {
        "id": "Rm0FZxDJgPVL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sess = gpt2.start_tf_sess()"
      ],
      "metadata": {
        "id": "vIv3oWCjigxB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_dir = 'models'\n",
        "gpt2.load_gpt2(sess, model_name='117M', checkpoint_dir=model_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8nt0ISUiyyZ",
        "outputId": "5aca3d43-2f22-4d8e-b369-dcacf5de9a01"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pretrained model models/117M/model.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.generate(sess, run_name='117M', checkpoint_dir=model_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "677LUJqiLuJg",
        "outputId": "08f1d89c-c6b4-4e24-b9f5-2532d09b9e0a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The problem is, may it not be a problem at all.\n",
            "\n",
            "The big problem? We're all confused about what goes on inside of a car. Why is it so hard to get a driver's license when you can get a driver's license at a DMV? Why does it take two years for a car to get going?\n",
            "\n",
            "Well, it's a little harder to get a driver's license than it is to get an auto insurance policy. But if you're living in Missouri, you're not going to be stuck with a $1,000 car insurance policy.\n",
            "\n",
            "The problem is, it's not just cost.\n",
            "\n",
            "Many people are seeing this as a problem, and it's time for us to start talking about it.\n",
            "\n",
            "I have a problem with the idea that someone should pay for a car insurance policy.\n",
            "\n",
            "I have a problem with the idea that people should be allowed to choose between a car insurance policy and driving privileges, and that's not a good idea.\n",
            "\n",
            "What would happen if some of us decided to get our own car insurance?\n",
            "\n",
            "I would lose my job, my ability to drive a car, my health, my freedom to drive a car.\n",
            "\n",
            "I would lose my benefits, my ability to pay for my car insurance, my ability to pay for my insurance, my freedom to drive a car, my freedom to drive a car.\n",
            "\n",
            "The two things that are the most difficult to get a car insurance policy to a customer are:\n",
            "\n",
            "You have to pay for a car insurance policy that will cover you if you drive for five years (this is an illegal limit for most car insurers under Missouri law).\n",
            "\n",
            "You have to pay for a car insurance policy that will cover you if you drive for five years (this is an illegal limit for most car insurers under Missouri law). You can't drive a car.\n",
            "\n",
            "In fact, you can't drive a car unless you're driving for a specified length of time, or for a specified amount of time, or for a specified amount of time.\n",
            "\n",
            "This means you can't get a car insurance policy without paying for it.\n",
            "\n",
            "If you start a car insurance policy, you're in for a shock, because you cannot get a car insurance policy without paying for it.\n",
            "\n",
            "If you start a car insurance policy, you're in for a shock, because you cannot get a car insurance policy without paying for it. And if you want to drive a car, you're in for a shock because you cannot get a car insurance policy without paying for it.\n",
            "\n",
            "This means you can't get a car insurance policy without paying for it. The law doesn't require you to pay for a car insurance policy.\n",
            "\n",
            "The law doesn't require you to pay for a car insurance policy. And if you want to drive a car, you're in for a shock because you cannot get a car insurance policy without paying for it.\n",
            "\n",
            "Now, if you want to get a car insurance policy, you need to pay for it.\n",
            "\n",
            "Now, if you want to get a car insurance policy, you need to pay for it.\n",
            "\n",
            "Now, if you want to get a car insurance policy, you need to pay for it.\n",
            "\n",
            "Yes, you can get a car insurance policy without paying for it.\n",
            "\n",
            "Yes, you can get a car insurance policy without paying for it.\n",
            "\n",
            "No, you can't get a car insurance policy without paying for it.\n",
            "\n",
            "What if you don't get a car insurance policy?\n",
            "\n",
            "You'd have to pay for a car insurance policy with the loss of your job.\n",
            "\n",
            "If you get a car insurance policy after five years of driving, you're left with a $1,000 car insurance policy.\n",
            "\n",
            "I'm going to lay out what a car insurance policy is and what it actually costs.\n",
            "\n",
            "Under Missouri law, a car insurance policy is a policy that covers a person's personal coverage.\n",
            "\n",
            "Qualifying as a car insurance policy is a condition that requires the car insurance company to cover the policy.\n",
            "\n",
            "If you're not eligible for a car insurance policy, you won't be able to get a car insurance policy.\n",
            "\n",
            "So what's the problem?\n",
            "\n",
            "You can get a car insurance policy without paying for it.\n",
            "\n",
            "You can get a car insurance policy without paying for it.\n",
            "\n",
            "You can get a car insurance policy without paying for it.\n",
            "\n",
            "You can get a car insurance policy without paying for it.\n",
            "\n",
            "You can get a car insurance policy without paying for it.\n",
            "\n",
            "You can get a car insurance policy without paying for it.\n",
            "\n",
            "You can get a car insurance policy without paying for it.\n",
            "\n",
            "You can get a car insurance policy without paying for it.\n",
            "\n",
            "You can get a car insurance policy without paying for it.\n",
            "\n",
            "You can get a car insurance policy without paying for it.\n",
            "\n",
            "You can get a car insurance policy without paying for\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.generate(sess,\n",
        "              run_name='117M',\n",
        "              checkpoint_dir=model_dir,\n",
        "              length=100,          # Number of tokens in the generated text\n",
        "              temperature=0.7,     # Controls creativity (lower = more focused, higher = more creative)\n",
        "              top_k=40,            # Limits sampling to the top-k tokens (for coherence)\n",
        "              top_p=0.9,           # Cumulative probability to control coherence and diversity\n",
        "              prefix=\"Once upon a time\",  # Text prompt to start the generation\n",
        "              nsamples=3,          # Number of samples to generate\n",
        "              batch_size=1,        # Number of samples to generate in parallel\n",
        "              return_as_list=True  # If True, returns the output as a list\n",
        "              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAv2aRBpZIG4",
        "outputId": "5bb297b6-d632-49bc-a312-ff1cfbdb047a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Once upon a time, you could think of the other planet as the world of the sun. The planet was never more than a satellite of the Sun. That's why we see it as a ring of stars. When the sun went out, it didn't go in and out.\\n\\nNow, to the question: Why is the universe so small? Because the universe is so small. And it's easy to say that. If you look at the stars, the stars are large. But if you look at\",\n",
              " \"Once upon a time, the humans had all of the energy of a giant, but they were all too close to the giants' homes. The humans were about to become the world's first humans, and when the Humans stopped the giant, they had to wait for the Humans to return.\\n\\nThe humans could not get through this. As they had seen from the humans, the humans had no choice but to wait. They would have to make it back to the humans, but they were still going to have to\",\n",
              " 'Once upon a time, the street was still and even now, it was a place of constant walking and walking.\\n\\nIt was a place where the sun shone on a large chunk of the street, where the people of the city were enjoying themselves. The people of the city were laughing and joking with one another. They were enjoying themselves in this place.\\n\\n\"I\\'m sure I\\'ll be able to find a good meal, and I\\'ll have a good time.\"\\n\\nWhen a man from the city']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.generate(sess,\n",
        "              run_name='117M',\n",
        "              checkpoint_dir=model_dir,\n",
        "              length=50,          # Number of tokens in the generated text\n",
        "              temperature=0.2,     # Controls creativity (lower = more focused, higher = more creative)\n",
        "              top_k=50,            # Limits sampling to the top-k tokens (for coherence)\n",
        "              top_p=0.9,           # Cumulative probability to control coherence and diversity\n",
        "              prefix=\"I love data science because\",  # Text prompt to start the generation\n",
        "              nsamples=3,          # Number of samples to generate\n",
        "              batch_size=1,        # Number of samples to generate in parallel\n",
        "              return_as_list=False  # If True, returns the output as a list\n",
        "              )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTQdXPOCZIBx",
        "outputId": "77fd112a-8871-4823-f948-fb193dde8ab0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I love data science because it's so easy to understand and understand. It's a lot easier to understand than to understand the data.\n",
            "\n",
            "I love data science because it's so easy to understand and understand. It's a lot easier to understand than to understand the data\n",
            "====================\n",
            "I love data science because it's easy to understand and it's easy to understand.\n",
            "\n",
            "I love data science because it's easy to understand and it's easy to understand.\n",
            "\n",
            "I love data science because it's easy to understand and it's easy to understand.\n",
            "====================\n",
            "I love data science because it's easy to understand and it's easy to understand how to use it. But I'm not sure that it's the right way to do it.\n",
            "\n",
            "I think that the best way to do it is to have a database of all the\n",
            "====================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine Tuning GPT2"
      ],
      "metadata": {
        "id": "pbtxqHvfTmki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://www.gutenberg.org/files/84/84-0.txt\"  # Example: Frankenstein by Mary Shelley\n",
        "response = requests.get(url)\n",
        "\n",
        "Frankenstein_book = response.text\n"
      ],
      "metadata": {
        "id": "NMg6DcQ3ZH5Y"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('fine_tuning_data.txt', 'w') as f:\n",
        "    f.write(Frankenstein_book)"
      ],
      "metadata": {
        "id": "lDT8As-MWwuR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.reset_default_graph()\n",
        "finetune_sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(finetune_sess, model_name='117M', checkpoint_dir=model_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQiLEV-TYXez",
        "outputId": "15937608-137b-40bf-9995-7b4883c9db05"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pretrained model models/117M/model.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.finetune(finetune_sess,\n",
        "               'fine_tuning_data.txt',\n",
        "               model_name='117M',\n",
        "               steps=1000,\n",
        "               restore_from='latest',  # or 'latest' if applicable\n",
        "               run_name='unique_run_name',\n",
        "               print_every=10,\n",
        "               sample_every=200,\n",
        "               save_every=500,\n",
        "               reuse=True)  # Add reuse=True here\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVgM5g7zXzld",
        "outputId": "9c98731d-91af-4fde-ccdb-fe6f8035bfbd"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/117M/model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|                                                                        | 0/1 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r100%|████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 106176 tokens\n",
            "Training...\n",
            "[10 | 25.98] loss=3.22 avg=3.22\n",
            "[20 | 48.59] loss=2.67 avg=2.94\n",
            "[30 | 71.37] loss=3.20 avg=3.03\n",
            "[40 | 93.85] loss=2.77 avg=2.96\n",
            "[50 | 116.32] loss=3.07 avg=2.99\n",
            "[60 | 138.91] loss=2.69 avg=2.93\n",
            "[70 | 161.53] loss=2.88 avg=2.93\n",
            "[80 | 184.10] loss=2.51 avg=2.87\n",
            "[90 | 206.65] loss=2.52 avg=2.83\n",
            "[100 | 229.16] loss=2.64 avg=2.81\n",
            "[110 | 251.70] loss=2.45 avg=2.78\n",
            "[120 | 274.25] loss=2.28 avg=2.73\n",
            "[130 | 296.81] loss=2.03 avg=2.68\n",
            "[140 | 319.37] loss=2.24 avg=2.64\n",
            "[150 | 341.94] loss=1.77 avg=2.58\n",
            "[160 | 364.50] loss=1.37 avg=2.50\n",
            "[170 | 387.05] loss=1.58 avg=2.44\n",
            "[180 | 409.60] loss=1.53 avg=2.39\n",
            "[190 | 432.16] loss=1.54 avg=2.34\n",
            "[200 | 454.74] loss=1.58 avg=2.30\n",
            "======== SAMPLE 1 ========\n",
            " of our youth, and\n",
            "they have suffered greatly from my neglect. But, dear Victor,\n",
            "know me not by the title, or rather the habitation of my\n",
            "machinations, and do not you suppose that I took delight in my\n",
            "disposition?”\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "August 7th, 17—.\n",
            "\n",
            "\n",
            "My dear girl, I never could so lamentably well as to leave\n",
            "my father, my devoted mother, and Elizabeth in penury as I did\n",
            "now do. I do not pretend to detail all the torments that\n",
            "have been my illustrious sufferings endure. I know that, in spite of myself,\n",
            "I cannot\n",
            "pile my soul with the enticements of vice. But in spite of myself I\n",
            "can boast of the pardoning influence of vice. The very idea of\n",
            "this society, the love and attachment of fellowship that bestowed\n",
            "it, gives virtue to a state of being so unlike the passions of\n",
            "nature. The only consolation I shall ever feel is that the friends that\n",
            "suppose me do not wish me to be the cause of their desolation. I\n",
            "shall ever live in a world in which I shall be grateful for the\n",
            "guiltlessness of my actions. I shall never be degraded by them.\n",
            "\n",
            "Nor shall I ever regret, when my actions are innocent and I be condemned\n",
            "by them. My sins shall not endure, but they shall not\n",
            "be regarded as guiltless, as the fault of my fellow beings.”\n",
            "\n",
            "I now turn to the subject of my journal.\n",
            "\n",
            "The morning of the 11th, my father and Elizabeth had departed for\n",
            "the beach with me and me to rest. I hardly remembered the occurrences\n",
            "of that day, but I wrote often of the delightful view of\n",
            "the Marais and heard the mournful exhortations of my father, as the day and\n",
            "time passed away. It was thus that I related my misfortunes.\n",
            "\n",
            "I am surrounded by misery, yet others tremble at my narration.\n",
            "Poor Victor! he is poor—poor, poor, poor, poor! Poor, poor, poor,\n",
            "poor, poor, very ill. Poor, very ill, indeed, very ill. His fever is\n",
            "rising fast, and he is now thus malnourished, with feverish fits and\n",
            "dark mists. On the 11th he went forth on a journey, the eye of the\n",
            "nose upon his lips. He was hailed as brave and resourceful, a\n",
            "creature whom the generous hearts of men could have selected for their\n",
            "valor and excellence. When he recovered and was hailed as the worthy and\n",
            "benefactor of his kind, a crowd gathered around him to jeer and jeer him. He\n",
            "was indignant and would have led a more cordial life than his\n",
            "disposition, but his voice was hoarser than his countenance. I\n",
            "listened to his tale and did not detect the rage that enveloped me.\n",
            "As the sun sank beneath the horizon, I rose; the blue sky was dark, and\n",
            "slight rain poured from a rich source; I felt a kind of light despond; and\n",
            "I felt fury, despair, and a desire to destroy as many feet of water as\n",
            "I could in what was to me the very resemblance of a dry land.\n",
            "Ruined and homeless, I felt the utmost fatigue and the greatest\n",
            "despair. I must destroy my people, and they alone can survive.\n",
            "All that I had loved and valued in my whole life is gone; and I\n",
            "must destroy my people, and they alone can survive.”\n",
            "\n",
            "These words agitated me, and I placed my hands before my eyes as I\n",
            "descended the steps of the professor. I looked on him with\n",
            "unearthly look-alike compassion and looked on his immoderate face as I\n",
            "thought my native. Professor Peters was a gentle and kind being, deeply\n",
            "acquainted with the feelings and dispositions of the beings he taught\n",
            "and had acquired an astonishing knowledge of the world. He appeared\n",
            "to have no passions or cares at all for a life of relative\n",
            "content, for in his discourses he had not abandoned his students nor\n",
            "promised them eternal happiness. On his lips he had eloquently and directly\n",
            "expressed those heartfelt sentiments which most philosophers endeavour to instil\n",
            "in men. His discourse was conversably short, for it was not the last\n",
            "word of the professor that a student should understand. When he had finished,\n",
            "the student should look on the professor with the same care and reverence\n",
            "that a child gives to their elder brother, which student alone can\n",
            "understand and who should engage him in learning? For this reason I was deeply\n",
            "acquainted with his history and should speak with profound knowledge\n",
            "of its consequences.\n",
            "\n",
            "“This professor is more excellent than his pupils know him to be, and it\n",
            "is true that his manner is more agreeable to\n",
            "\n",
            "[210 | 489.67] loss=1.25 avg=2.24\n",
            "[220 | 512.24] loss=0.91 avg=2.17\n",
            "[230 | 534.85] loss=0.74 avg=2.10\n",
            "[240 | 557.45] loss=0.45 avg=2.03\n",
            "[250 | 580.03] loss=1.01 avg=1.98\n",
            "[260 | 602.61] loss=0.87 avg=1.93\n",
            "[270 | 625.17] loss=0.83 avg=1.89\n",
            "[280 | 647.74] loss=0.53 avg=1.83\n",
            "[290 | 670.31] loss=0.36 avg=1.77\n",
            "[300 | 692.86] loss=0.28 avg=1.71\n",
            "[310 | 715.42] loss=0.27 avg=1.66\n",
            "[320 | 737.99] loss=0.29 avg=1.61\n",
            "[330 | 760.55] loss=0.26 avg=1.56\n",
            "[340 | 783.11] loss=0.22 avg=1.52\n",
            "[350 | 805.66] loss=0.31 avg=1.48\n",
            "[360 | 828.24] loss=0.19 avg=1.43\n",
            "[370 | 850.83] loss=0.18 avg=1.39\n",
            "[380 | 873.46] loss=0.15 avg=1.35\n",
            "[390 | 896.02] loss=0.15 avg=1.32\n",
            "[400 | 918.57] loss=0.14 avg=1.28\n",
            "======== SAMPLE 1 ========\n",
            "of\n",
            "the human frame, the expression of your thoughts and actions was the same\n",
            "where I obtained the object of my desire; but where was the\n",
            "friend or relative whom I wished to avoid? By different means I narrowed my search,\n",
            "but one by one, I came up against the objects which I thought would\n",
            "interest me the most. I remember wandering through the woods with one\n",
            "ook in my hand, looking up into the heavens; what would be my\n",
            "relation or connection with the creatures of the opposite sex? My soul\n",
            "was full of inquisitiveness and endless search, but I was overcome by the\n",
            "obscene of futility. I placed the picture under my wing, but he came crawling\n",
            "up distant to aid me. I could hardly protect him, for as I touched\n",
            "the pathless ground he paused and seemed to lose all his\n",
            "coercion, but I drew near to his grasp and desired him to remain,\n",
            "but that he should quickly return. As soon as I was able to do, he\n",
            "approached me and said, “My dearest friend, you will not believe\n",
            "in my unworthiness to come and besmirch my dearest friend, must you?.'\n",
            "\n",
            "I lost the stranger in sobs, but I endeavoured to persuade him to take me\n",
            "along with him, and soothe me with story after story. He looked as if he\n",
            "had for a long time been at peace, but when he heard of my tale, he\n",
            "hardened, “ that I wished to declare myself guilty, that I\n",
            "indeed could not love him, but that I desired to be forgotten, that I\n",
            "swear he would not find me bereft again except in the agony of my crime.\n",
            "\n",
            "He fell under one of my wing, and I soon saw him again in the broad white\n",
            "sea; but by the irregularity of the season, the weather, and,\n",
            "more than all, the clouds, which changed the seasons, I should not\n",
            "have been able to judge of them.\n",
            "\n",
            "“I know of one time,” said he, “when I saw a cloud lose\n",
            "herself beneath it, a man in a fair dress, walking in the beach.\n",
            "A man of lofty character, standing in the beach orde, stretched before\n",
            "you his arms. He was dressed in a fair colour, but his countenance\n",
            "was gloomy and melancholy. Some think he is the devil, but I\n",
            "have no proof. He walks in the town, speaks to no one, never visits\n",
            "the beach; is it not strange that he should approve of such a\n",
            "strangerageage sound? There is a murmur in the old town that he might\n",
            "approach, and I longed to visit him, but I was overcome by the sensation\n",
            "of dread and knew that I ought not to hope for escape, but in\n",
            "one of those dark regions in which the sun cannot shine; dread and despair\n",
            "were the ugliest sensations I had ever experienced; I knew that I\n",
            "must get out of here; I knew that if I should be apprehended I\n",
            "was ever destined to be in prison or long be condemned to suffer hard labour and\n",
            "death. The sun had farrowed itself before my door, and it appeared that I\n",
            "might as well have been alive to intrude myself into a personne s house\n",
            "and prying open his or her door, wished I could see what he or she was\n",
            "on the great road to freedom; that would have been murder to me, but I\n",
            "remembered that I should have found it murder to the very stars!\n",
            "\n",
            "“Yet a moment ago I knelt on the beach and in a dream fancied my\n",
            "journey complete, and perceiving me, exclaimed, “Have you now lost\n",
            "the popular cheerleading squad that morning? You ran on, my friend, and I\n",
            "reached the top of the class. Miserable, I regret it; I also feel the\n",
            "greatest remorse. I had rather entered the company of a criminal, who\n",
            "molested me, and had tortured me with the bitterness and death I\n",
            "saved by my repentance than received me in his arms for his crimes.”\n",
            "\n",
            "“But it was not thus. During the whole period that I was\n",
            "indifferent to the interest which my friends hoped for in me, the\n",
            "week passed in a strange order; the more I looked upon the prospect of\n",
            "wishing to become as he is, the more strongly I wished to be watched and\n",
            "contemplated. I looked upon him as impracticable, extremely difficult to\n",
            "master; but in the extreme regions of the earth men allowed it to be perceived,\n",
            "and many\n",
            "gradually discovered the purpose of these academies. They were for\n",
            "apparently criminal purposes, and the detested gaol at Ingolstadt. My\n",
            "exam, or rather unhappy, state\n",
            "\n",
            "[410 | 952.38] loss=0.12 avg=1.25\n",
            "[420 | 974.92] loss=0.10 avg=1.21\n",
            "[430 | 997.50] loss=0.14 avg=1.18\n",
            "[440 | 1020.08] loss=0.11 avg=1.15\n",
            "[450 | 1042.69] loss=0.12 avg=1.13\n",
            "[460 | 1065.31] loss=0.09 avg=1.10\n",
            "[470 | 1087.89] loss=0.08 avg=1.07\n",
            "[480 | 1110.44] loss=0.09 avg=1.04\n",
            "[490 | 1133.00] loss=0.07 avg=1.02\n",
            "[500 | 1155.56] loss=0.07 avg=1.00\n",
            "Saving checkpoint/unique_run_name/model-500\n",
            "[510 | 1182.58] loss=0.10 avg=0.97\n",
            "[520 | 1205.29] loss=0.07 avg=0.95\n",
            "[530 | 1227.80] loss=0.12 avg=0.93\n",
            "[540 | 1250.33] loss=0.06 avg=0.91\n",
            "[550 | 1272.95] loss=0.07 avg=0.89\n",
            "[560 | 1295.50] loss=0.09 avg=0.87\n",
            "[570 | 1318.05] loss=0.08 avg=0.85\n",
            "[580 | 1340.67] loss=0.05 avg=0.84\n",
            "[590 | 1363.30] loss=0.08 avg=0.82\n",
            "[600 | 1385.88] loss=0.09 avg=0.80\n",
            "======== SAMPLE 1 ========\n",
            " in the night and we stayed the day. It was at that time that I learned the importance of being\n",
            "visited by Cornelius Agrippa and Paracelsus.\n",
            "\n",
            "On the third day I ascended to the top of the mountain. The stream was\n",
            "clouded in every direction and every direction not to be\n",
            "understood in the same sense, for I was on a clear day. It was\n",
            "cold. I could feel the chill waves rushing across the surrounding\n",
            "shelves and I imagined the sailors whirled round them, as if\n",
            "they saw a vision of the disaster engulfing them. I also\n",
            "beheld the torments of night, the work of the hands of time, the\n",
            "painful contrast of day and night, the light and shadow of morning and\n",
            "darkness.\n",
            "\n",
            "“The ascent is very precipitous; you need not have taken any other than a\n",
            "good will and a curiosity to ascend. The valley is very || fertile, for in the midst of the\n",
            "snowy mountains that rise from the hills, and many lovely curbs step on\n",
            "it. From this vantage the wind blows slowly, and the storm\n",
            "has a low whine and a loud click as it passes through, while the\n",
            "pedestrian, horse, or carriage follows unhindered. In this manner many\n",
            "animals were borne away by the sight of the dashing glacier and\n",
            "shore of the most beautiful country I had ever seen. I took in\n",
            "thereas the view of the tremendous Pacific Ocean, which reflects its waters\n",
            "sobrightly in its varied colours and shapes. I paused to consider\n",
            "on my guest’s thoughts as he passed, and then proceeded to\n",
            "describe his occupation, his color, hiscolour, as he ascended the\n",
            "mountain’s Labyrinth.\n",
            "\n",
            "“His eyes wandered on every object that might interest him, and\n",
            "therefore he seemed to desire a country where nothing is known but\n",
            "the sensations of hunger and thirst. He sat\n",
            "down at one night’s meal and was absorbed in one\n",
            "thought, which formed the beginning of something beautiful. An\n",
            "instrumental mind wandered within the mind of this wretch. When\n",
            "he awoke, he found that the window of the room was open, and on the\n",
            "head, a small drawing Klimnos the Magnificent appeared. He played\n",
            "the part of interest and delightedfully obeyed, as he had in\n",
            "the first hour of his employment.\n",
            "\n",
            "“The wretch then addressed the fellow. ‘Enter,’ he said,\n",
            "‘minute,’ it is neater here.’\n",
            "\n",
            "“You are not allowed to spend the whole night here, are you?’\n",
            "\n",
            "“Certainly; I am going to the forest that ye have seen (vaults); I\n",
            "intend to ocasionally see what appears to be the leaves of some herb;\n",
            "therefore I am not to be disturbed if any herb sting or kill me if\n",
            "I noticably retreats.’\n",
            "\n",
            "“And now,’ I exclaimed, ‘for the dear prey,’ d\n",
            "want. ‘for me,’ for I am to be the object of scorn and\n",
            "punishment.’\n",
            "\n",
            "“Do not reason with me,’ said the dæmon; ‘give up your\n",
            "dæmon, or I will become your miserable slave.’\n",
            "\n",
            "“And to you who know me,’ said the creature, ‘I am\n",
            "a chimera, but I was created to prejudice and hate, and\n",
            "to create a wall of cheese between you and my enemy.’\n",
            "\n",
            "“Yet I was not created that any harsh system might be endured.\n",
            "A sledge works thus, and in these last moments I\n",
            "engaged myself in the mise-en-scène, in which I blasted my dark\n",
            "imaginations against the dark mists of time. The sun was hot, and\n",
            "cold, and the clouds struggled to block the view; I saw the\n",
            "fancy of my creation destroyed by this world. The wretch who\n",
            "had loved me consume me saw only misery and devil\n",
            "nature in what was I.\n",
            "\n",
            "“After some days spent in this hell, when I again sat\n",
            "down and thought what I had to say, I found myself joined to\n",
            "the vaults of my hovel, clambering towards the winds. They had\n",
            "closed against me immediately; I felt the cold against me as I spoke;\n",
            "but it was absorbed by me by an intense and overwhelming\n",
            "wool.\n",
            "\n",
            "“The sun rose; I saw the chill water rise; the scene was\n",
            "suddenly clear, and I felt the last drops of snow\n",
            "fall. .’ What did this mean? I sat up, examined the\n",
            "snowy heavens and found it covered with\n",
            "\n",
            "[610 | 1419.61] loss=0.07 avg=0.79\n",
            "[620 | 1442.17] loss=0.08 avg=0.77\n",
            "[630 | 1464.72] loss=0.07 avg=0.76\n",
            "[640 | 1487.30] loss=0.06 avg=0.74\n",
            "[650 | 1509.92] loss=0.06 avg=0.73\n",
            "[660 | 1532.51] loss=0.07 avg=0.71\n",
            "[670 | 1555.06] loss=0.06 avg=0.70\n",
            "[680 | 1577.61] loss=0.08 avg=0.69\n",
            "[690 | 1600.16] loss=0.06 avg=0.68\n",
            "[700 | 1622.72] loss=0.08 avg=0.66\n",
            "[710 | 1645.29] loss=0.07 avg=0.65\n",
            "[720 | 1667.89] loss=0.06 avg=0.64\n",
            "[730 | 1690.49] loss=0.06 avg=0.63\n",
            "[740 | 1713.07] loss=0.07 avg=0.62\n",
            "[750 | 1735.62] loss=0.07 avg=0.61\n",
            "[760 | 1758.16] loss=0.07 avg=0.60\n",
            "[770 | 1780.71] loss=0.06 avg=0.59\n",
            "[780 | 1803.26] loss=0.06 avg=0.58\n",
            "[790 | 1825.84] loss=0.07 avg=0.57\n",
            "[800 | 1848.45] loss=0.08 avg=0.56\n",
            "======== SAMPLE 1 ========\n",
            " imagination—for there was a great\n",
            "penalty imposed on every act of ingratitude. Never did I feel too well,\n",
            "although I was cheered on, by the spirit of justice that surrounded me. Never\n",
            "did I so much as murmur in surprise, although I was delighted by\n",
            "the results.\n",
            "\n",
            "“These feelings induced me to apply to the philosophers, the alchemists,\n",
            "the perhaps less philosophers, the men of science employed in the most\n",
            "difficult of occupations. The men employed in this occupation, on\n",
            "both ends of the spectrum, were kindnessible and kind; but the\n",
            "physicists, whose occupations were so extensive, they were\n",
            "often mistreated, so that I was sent to hide among those who\n",
            "knew me poor. In this manner I became the victim of insatiate\n",
            "insulgence. I had hired a boat to convey me away, and to\n",
            "shore at anchor when the well-known whaler, the William, arrived,\n",
            "so that I might examine the depths of its criminal vice. I\n",
            "must sail into the open sea and put my feet entirely to the market-meat.\n",
            "But that is not what this is. This is a journey that I shall make,\n",
            "and amen! I wish to make friends and find a storehouse for my\n",
            "imagination. If I succeed, I shall despise Providence and its\n",
            "criminal delights and render them all to you as a holiday from me shall\n",
            "open.”\n",
            "\n",
            "I shuddered to think that in this hopeless task I should rob myself\n",
            "of all my delight and ability. I must work, as the scion of an evil\n",
            "and a pest over the well-being of my cousin. The task at\n",
            "hand is not much greater than that of creation; I must work, as the\n",
            "museiful child who encouraged me in my studies. Shall I create,\n",
            "or not create? My labours prove more painful and more horrible to me;\n",
            "but at least I am getting out of this wretched predicament. I have one still to\n",
            "be dreaded, and I am determined to meet it. If not, I will quit this world,\n",
            "or at least within the habitable zone of another race of beings.”\n",
            "\n",
            "She then related that she had so miserably wasted her life that she\n",
            "could not sustain the journey, and that she was using her whole power\n",
            "to procure food and clothes. When she arrived in Italy she found\n",
            "that the immense walls of Asia were vacant, and all around her was\n",
            "a scene of carnage and misery. A thousand shrieks of anguish and\n",
            "loathing filled the room. Half frightened, half filled with despair,\n",
            "I gave in, and gave up my undertaking. The sun rose; the heavens\n",
            "shone with light; the moons are darkened, and the dawning of a new\n",
            "night is yet to dawn. The green hills, which you raised\n",
            "for the ceremony of rising, are gone; the meadows have been\n",
            "remade, the trees restored, the herds of snowy deer, the\n",
            "lake of snow, the waters of Volga, the mountains of Pannon,\n",
            "and the dashing of the waves—all with a feeling of dreadful\n",
            "remorse and solemnity that gave me pleasure.\n",
            "\n",
            "But I was not immured in plans, and my rambles were curt. I\n",
            "fixed a sail with which I could skim over the innumerable\n",
            "sides of the lake, and fearing the encounter, pressed on,\n",
            "until night came. As it came, I saw a multitude of men, sledging\n",
            "along at speed, eagerly awaiting their turn. But what was I? They\n",
            "swimmed along with me, but I saw only ice. Theirs was a difference of\n",
            "feeling, and I was encouraged by their spirits, but they were cold; no\n",
            "fatness was theirs, but that of the world.\n",
            "\n",
            "I was soon overcome by the idea of what to do. Before I had\n",
            "everyday gained a sufficiently considerable distance from my native country, I\n",
            "must travel nearly a hundred miles across immense ice, to which almost every\n",
            "other topic was subordinated. I had never, before, seen a man\n",
            "so desolate and miserable. Yet it was the right instinct of my soul to\n",
            "extricate me from the effects of my own sensations. I kept a\n",
            "list of the most frequently visited caves and lakes, and I checked, as I\n",
            "fuored in the energy of our spirits, the dim and desolate light of the\n",
            "window of opportunity; but when I considered that the light of the\n",
            "window was nearly extinguished, the scenes around me became clear and\n",
            "greater than I had imagined. I saw the pale yellow of the northern\n",
            "lake, the red of the mountains, and the glow of the clear sky; I\n",
            "began to reflect on the other sights I had chosen, and my resolution was\n",
            "sustained by this remembrance.\n",
            "\n",
            "But\n",
            "\n",
            "[810 | 1882.21] loss=0.06 avg=0.55\n",
            "[820 | 1904.72] loss=0.05 avg=0.54\n",
            "[830 | 1927.26] loss=0.06 avg=0.53\n",
            "[840 | 1949.80] loss=0.06 avg=0.53\n",
            "[850 | 1972.34] loss=0.06 avg=0.52\n",
            "[860 | 1994.92] loss=0.06 avg=0.51\n",
            "[870 | 2017.49] loss=0.06 avg=0.50\n",
            "[880 | 2040.05] loss=0.05 avg=0.49\n",
            "[890 | 2062.65] loss=0.06 avg=0.49\n",
            "[900 | 2085.24] loss=0.07 avg=0.48\n",
            "[910 | 2107.80] loss=0.06 avg=0.47\n",
            "[920 | 2130.40] loss=0.05 avg=0.47\n",
            "[930 | 2153.02] loss=0.06 avg=0.46\n",
            "[940 | 2175.61] loss=0.05 avg=0.45\n",
            "[950 | 2198.19] loss=0.05 avg=0.45\n",
            "[960 | 2220.79] loss=0.06 avg=0.44\n",
            "[970 | 2243.37] loss=0.06 avg=0.43\n",
            "[980 | 2265.96] loss=0.05 avg=0.43\n",
            "[990 | 2288.54] loss=0.06 avg=0.42\n",
            "[1000 | 2311.13] loss=0.05 avg=0.42\n",
            "Saving checkpoint/unique_run_name/model-1000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/saver.py:1068: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"It was a cold dark night\"\n",
        "\n",
        "gpt2.generate(finetune_sess,\n",
        "               prefix=prompt,\n",
        "               length=100,\n",
        "               temperature=0.7,\n",
        "               top_k=40,\n",
        "               top_p=0.9,\n",
        "               run_name='unique_run_name')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKkDUJvmkqag",
        "outputId": "168aed92-d869-4761-c12d-6e853dc273cc"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It was a cold dark night, and I felt as if I had\n",
            "been strangled to death. The bolt was aimed at the shoulder, and I heard it\n",
            "as I sat motionless on the ground, my eyes still fixed on the pistol which was\n",
            "markeding my neck. The bolt sank, and I beheld a fiend within\n",
            "my wing; a wretch who had just struck me with his grasp, I dashed with\n",
            "pain to the ground, and heaped scorn and gnashing of teeth on every\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimenting with a 2nd Pre-trained model: Bert"
      ],
      "metadata": {
        "id": "8EJX7M8zlD6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqoKBj5Jk0pb",
        "outputId": "c2fc44a6-644e-4a97-e86e-5859fffee307"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EDYsgl2KnDP",
        "outputId": "f1c0a0eb-b7d1-4718-ed16-2eeb1efb975f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading datasets-3.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-3.0.2 dill-0.3.8 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load a subset of the IMDb dataset\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "# Load BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the data\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=128)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    report_to='none',\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'].shuffle(seed=42).select(range(2000)),\n",
        "    eval_dataset=tokenized_datasets['test'].shuffle(seed=42).select(range(500)),\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497,
          "referenced_widgets": [
            "a52e1419653448c0a1d02c850a9e6714",
            "47e71f01646f406d81110e9ac4f20988",
            "7281836530ef49b3988d429738522b2c",
            "5baedd38fa82425c90dcbb9aa25384c1",
            "43195b55cced44fca1ed443973084da1",
            "75a27512224f4664bf433bf462d8abc6",
            "f0dcbbb4cd014b70af80881fd7d43e04",
            "a9a004c91bde433685eff174409b0863",
            "32114fa780584d87b4097d45438ff48c",
            "c596b3e6d09544f48e8d525df7b0bc6e",
            "cda4621fcbbb4285a168a75738e80b59",
            "d9faf3b74c164054b8749917bfc2522e",
            "e216901558a644a2b47d9fccc9bb6682",
            "7eb0201eef9e489082fe9a7d3f18b6c3",
            "11982e1865b94aa38348de5fb2585014",
            "fe7092454eb646f2804dce8f442edc03",
            "b3d6a026a0264784b95df1a8d41a1f42",
            "9da55550079c49d2b6011f95bfafb271",
            "a6d6bd0438604a2fb304570164f75469",
            "dd1e78f2f4ff4e7face21334e5e5ce4d",
            "cd7702cd7c264ed1b7cb7924d69618d5",
            "7e84e6ea3f4e497fbc6dd89550d4eff3",
            "7b10c3848b9b4bfc838a09c198ffc869",
            "09829ac1e9524d34a4e38b2062b85c5b",
            "7169c200e0e14057a3ffcfe2f5b38853",
            "55bcb28cbcee4eb792ddf34cd72f76e7",
            "8170889bfbdc44e6b34800a25585e8b7",
            "b1802a71ac8e4b98bcefd8fb09695f0f",
            "5e8a023c3ad24d85b878f0a4c56a694c",
            "7895dbd4860941aeb386fb6dfb33baf2",
            "b405ed223daf4f58b131011d96efd64b",
            "fa81f29ef55446179976b4b21f9f82f0",
            "589ba806b5374836b607e8bb822cc734"
          ]
        },
        "id": "hcwwPpO8N30u",
        "outputId": "fa4ca392-3807-49e6-fdc3-e15163256971"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a52e1419653448c0a1d02c850a9e6714"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9faf3b74c164054b8749917bfc2522e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b10c3848b9b4bfc838a09c198ffc869"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 55:38, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.366503</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [63/63 03:33]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.3665033280849457,\n",
              " 'eval_runtime': 216.8379,\n",
              " 'eval_samples_per_second': 2.306,\n",
              " 'eval_steps_per_second': 0.291,\n",
              " 'epoch': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "test_samples = dataset['test']['text'][:5]\n",
        "\n",
        "inputs = tokenizer(test_samples, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "predictions = torch.nn.functional.softmax(logits, dim=-1)\n",
        "predicted_labels = torch.argmax(predictions, dim=1)\n",
        "\n",
        "for i, text in enumerate(test_samples):\n",
        "    print(f\"\\nReview: {text}\")\n",
        "    print(f\"Predicted label: {'Positive' if predicted_labels[i] == 1 else 'Negative'}\")\n",
        "    print(f\"Confidence scores: {predictions[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQQcd7hkUWpB",
        "outputId": "7a2563a9-30dd-4820-f41e-020bc0617669"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Review: I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn't match the background, and painfully one-dimensional characters cannot be overcome with a 'sci-fi' setting. (I'm sure there are those of you out there who think Babylon 5 is good sci-fi TV. It's not. It's clichéd and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It's really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it's rubbish as they have to always say \"Gene Roddenberry's Earth...\" otherwise people would not continue watching. Roddenberry's ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.\n",
            "Predicted label: Negative\n",
            "Confidence scores: tensor([0.8967, 0.1033])\n",
            "\n",
            "Review: Worth the entertainment value of a rental, especially if you like action movies. This one features the usual car chases, fights with the great Van Damme kick style, shooting battles with the 40 shell load shotgun, and even terrorist style bombs. All of this is entertaining and competently handled but there is nothing that really blows you away if you've seen your share before.<br /><br />The plot is made interesting by the inclusion of a rabbit, which is clever but hardly profound. Many of the characters are heavily stereotyped -- the angry veterans, the terrified illegal aliens, the crooked cops, the indifferent feds, the bitchy tough lady station head, the crooked politician, the fat federale who looks like he was typecast as the Mexican in a Hollywood movie from the 1940s. All passably acted but again nothing special.<br /><br />I thought the main villains were pretty well done and fairly well acted. By the end of the movie you certainly knew who the good guys were and weren't. There was an emotional lift as the really bad ones got their just deserts. Very simplistic, but then you weren't expecting Hamlet, right? The only thing I found really annoying was the constant cuts to VDs daughter during the last fight scene.<br /><br />Not bad. Not good. Passable 4.\n",
            "Predicted label: Positive\n",
            "Confidence scores: tensor([0.1671, 0.8329])\n",
            "\n",
            "Review: its a totally average film with a few semi-alright action sequences that make the plot seem a little better and remind the viewer of the classic van dam films. parts of the plot don't make sense and seem to be added in to use up time. the end plot is that of a very basic type that doesn't leave the viewer guessing and any twists are obvious from the beginning. the end scene with the flask backs don't make sense as they are added in and seem to have little relevance to the history of van dam's character. not really worth watching again, bit disappointed in the end production, even though it is apparent it was shot on a low budget certain shots and sections in the film are of poor directed quality\n",
            "Predicted label: Negative\n",
            "Confidence scores: tensor([0.9012, 0.0988])\n",
            "\n",
            "Review: STAR RATING: ***** Saturday Night **** Friday Night *** Friday Morning ** Sunday Night * Monday Morning <br /><br />Former New Orleans homicide cop Jack Robideaux (Jean Claude Van Damme) is re-assigned to Columbus, a small but violent town in Mexico to help the police there with their efforts to stop a major heroin smuggling operation into their town. The culprits turn out to be ex-military, lead by former commander Benjamin Meyers (Stephen Lord, otherwise known as Jase from East Enders) who is using a special method he learned in Afghanistan to fight off his opponents. But Jack has a more personal reason for taking him down, that draws the two men into an explosive final showdown where only one will walk away alive.<br /><br />After Until Death, Van Damme appeared to be on a high, showing he could make the best straight to video films in the action market. While that was a far more drama oriented film, with The Shepherd he has returned to the high-kicking, no brainer action that first made him famous and has sadly produced his worst film since Derailed. It's nowhere near as bad as that film, but what I said still stands.<br /><br />A dull, predictable film, with very little in the way of any exciting action. What little there is mainly consists of some limp fight scenes, trying to look cool and trendy with some cheap slo-mo/sped up effects added to them that sadly instead make them look more desperate. Being a Mexican set film, director Isaac Florentine has tried to give the film a Robert Rodriguez/Desperado sort of feel, but this only adds to the desperation.<br /><br />VD gives a particularly uninspired performance and given he's never been a Robert De Niro sort of actor, that can't be good. As the villain, Lord shouldn't expect to leave the beeb anytime soon. He gets little dialogue at the beginning as he struggles to muster an American accent but gets mysteriously better towards the end. All the supporting cast are equally bland, and do nothing to raise the films spirits at all.<br /><br />This is one shepherd that's strayed right from the flock. *\n",
            "Predicted label: Positive\n",
            "Confidence scores: tensor([0.2301, 0.7699])\n",
            "\n",
            "Review: First off let me say, If you haven't enjoyed a Van Damme movie since bloodsport, you probably will not like this movie. Most of these movies may not have the best plots or best actors but I enjoy these kinds of movies for what they are. This movie is much better than any of the movies the other action guys (Segal and Dolph) have thought about putting out the past few years. Van Damme is good in the movie, the movie is only worth watching to Van Damme fans. It is not as good as Wake of Death (which i highly recommend to anyone of likes Van Damme) or In hell but, in my opinion it's worth watching. It has the same type of feel to it as Nowhere to Run. Good fun stuff!\n",
            "Predicted label: Positive\n",
            "Confidence scores: tensor([0.1473, 0.8527])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lM5wBUdzm1SD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "text_generation_gpt",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a52e1419653448c0a1d02c850a9e6714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47e71f01646f406d81110e9ac4f20988",
              "IPY_MODEL_7281836530ef49b3988d429738522b2c",
              "IPY_MODEL_5baedd38fa82425c90dcbb9aa25384c1"
            ],
            "layout": "IPY_MODEL_43195b55cced44fca1ed443973084da1"
          }
        },
        "47e71f01646f406d81110e9ac4f20988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75a27512224f4664bf433bf462d8abc6",
            "placeholder": "​",
            "style": "IPY_MODEL_f0dcbbb4cd014b70af80881fd7d43e04",
            "value": "Map: 100%"
          }
        },
        "7281836530ef49b3988d429738522b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9a004c91bde433685eff174409b0863",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32114fa780584d87b4097d45438ff48c",
            "value": 25000
          }
        },
        "5baedd38fa82425c90dcbb9aa25384c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c596b3e6d09544f48e8d525df7b0bc6e",
            "placeholder": "​",
            "style": "IPY_MODEL_cda4621fcbbb4285a168a75738e80b59",
            "value": " 25000/25000 [02:41&lt;00:00, 156.68 examples/s]"
          }
        },
        "43195b55cced44fca1ed443973084da1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75a27512224f4664bf433bf462d8abc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0dcbbb4cd014b70af80881fd7d43e04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9a004c91bde433685eff174409b0863": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32114fa780584d87b4097d45438ff48c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c596b3e6d09544f48e8d525df7b0bc6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cda4621fcbbb4285a168a75738e80b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9faf3b74c164054b8749917bfc2522e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e216901558a644a2b47d9fccc9bb6682",
              "IPY_MODEL_7eb0201eef9e489082fe9a7d3f18b6c3",
              "IPY_MODEL_11982e1865b94aa38348de5fb2585014"
            ],
            "layout": "IPY_MODEL_fe7092454eb646f2804dce8f442edc03"
          }
        },
        "e216901558a644a2b47d9fccc9bb6682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3d6a026a0264784b95df1a8d41a1f42",
            "placeholder": "​",
            "style": "IPY_MODEL_9da55550079c49d2b6011f95bfafb271",
            "value": "Map: 100%"
          }
        },
        "7eb0201eef9e489082fe9a7d3f18b6c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6d6bd0438604a2fb304570164f75469",
            "max": 25000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd1e78f2f4ff4e7face21334e5e5ce4d",
            "value": 25000
          }
        },
        "11982e1865b94aa38348de5fb2585014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd7702cd7c264ed1b7cb7924d69618d5",
            "placeholder": "​",
            "style": "IPY_MODEL_7e84e6ea3f4e497fbc6dd89550d4eff3",
            "value": " 25000/25000 [02:42&lt;00:00, 153.14 examples/s]"
          }
        },
        "fe7092454eb646f2804dce8f442edc03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3d6a026a0264784b95df1a8d41a1f42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9da55550079c49d2b6011f95bfafb271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6d6bd0438604a2fb304570164f75469": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd1e78f2f4ff4e7face21334e5e5ce4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cd7702cd7c264ed1b7cb7924d69618d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e84e6ea3f4e497fbc6dd89550d4eff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b10c3848b9b4bfc838a09c198ffc869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09829ac1e9524d34a4e38b2062b85c5b",
              "IPY_MODEL_7169c200e0e14057a3ffcfe2f5b38853",
              "IPY_MODEL_55bcb28cbcee4eb792ddf34cd72f76e7"
            ],
            "layout": "IPY_MODEL_8170889bfbdc44e6b34800a25585e8b7"
          }
        },
        "09829ac1e9524d34a4e38b2062b85c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1802a71ac8e4b98bcefd8fb09695f0f",
            "placeholder": "​",
            "style": "IPY_MODEL_5e8a023c3ad24d85b878f0a4c56a694c",
            "value": "Map: 100%"
          }
        },
        "7169c200e0e14057a3ffcfe2f5b38853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7895dbd4860941aeb386fb6dfb33baf2",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b405ed223daf4f58b131011d96efd64b",
            "value": 50000
          }
        },
        "55bcb28cbcee4eb792ddf34cd72f76e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa81f29ef55446179976b4b21f9f82f0",
            "placeholder": "​",
            "style": "IPY_MODEL_589ba806b5374836b607e8bb822cc734",
            "value": " 50000/50000 [05:36&lt;00:00, 150.51 examples/s]"
          }
        },
        "8170889bfbdc44e6b34800a25585e8b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1802a71ac8e4b98bcefd8fb09695f0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e8a023c3ad24d85b878f0a4c56a694c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7895dbd4860941aeb386fb6dfb33baf2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b405ed223daf4f58b131011d96efd64b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa81f29ef55446179976b4b21f9f82f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "589ba806b5374836b607e8bb822cc734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}